---
layout  : wiki
title   : STREAM
summary : 
date    : 2025-05-27 08:02:32 +0900
updated : 2025-05-27 08:12:24 +0900
tag     : architecture stream
toc     : true
comment : true
public  : true
parent  : [[/architecture]]
latex   : true
---
* TOC
{:toc}

## STREAM

A ___[stream](https://en.wikipedia.org/wiki/Stream_(computing))___ represents data that is progressively produced over time. Unlike traditional batch processing where you work with finite datasets, streams deal with continuous, unbounded data flows that never truly "complete."

All streams across different domains share the fundamental essence of <mark><em><strong>"continuous data flow with real-time processing"!</strong></em></mark> Streams transform how we think about data: from "having data" to <mark><em><strong>"flowing data"</strong></em></mark> - enabling real-time, scalable, and resilient systems.

Users generate data yesterday, today, and will continue generating data as long as the service exists. This fundamental characteristic means that ___stream processing___ is essentially about handling infinite data processing scenarios.

Stream processing can operate in two main modes:
- **Time-windowed processing**: Processing data at fixed intervals (e.g., aggregating ad click events every minute)
- **Event-driven processing**: Processing data immediately as events occur, without fixed time boundaries

> All streams across different domains share the fundamental essence of ___"continuous data flow with real-time processing"!___ Streams transform how we think about data: from "having data" to ___"flowing data"___ - enabling real-time, scalable, and resilient systems.

All data processing systems operate with two distinct time concepts:
- **Event Time**: When the event actually occurred in the real world
- **Processing Time**: When the event was observed and processed by the system

> Data teams often require precise timestamps for when clients and servers send and receive events to maintain data integrity and enable accurate analysis.

## Event Organization and Messaging Systems in Stream Processing

When building systems like ad click event aggregation, you often work with log files distributed across multiple servers. The typical processing pipeline involves:

__File-Based Stream Processing__:
- Input Source: Log files scattered across distributed servers
- File Format: Input consists of files (sequence of bytes) from various sources
- Parsing Stage: The first step typically involves analyzing files and converting them into a sequence of records
- Record Processing: Each record becomes a unit of processing in the stream

In stream processing terminology, these records are commonly referred to as ___[EVENT](https://klarciel.net/wiki/architecture/architecture-event/)___.

__Stream systems organize related events using__:
- Topics: Logical groupings of similar events
- Subjects: Alternative term for topics in some systems
- Streams: The actual data flow channels

To notify consumers about new events, stream systems rely on ___Messaging Systems___ that implement various delivery patterns.

### Key Design Questions for Pub/Sub Systems

When designing ___[Publish/Subscribe System](https://klarciel.net/wiki/architecture/architecture-pub-sub/)___, two critical questions help determine the appropriate architecture:

#### Handling Producer-Consumer Speed Mismatch

What happens when producers send messages faster than consumers can process them?

- __Option A: Drop Messages__
   - enable to data loss (message throwing)
   - Suitable for non-critical, high-volume scenarios
- __Option B: Buffer in Queue (Backpressure/Flow Control)__
   - Strategy used by Unix Pipes and TCP
   - Maintains a small, fixed-size buffer
   - Blocks sender when buffer is full until receiver consumes data
- __Option C: Block Producer__
  - Prevents the producer from sending additional messages
  - Avoids message loss but can create system bottlenecks

__Critical Buffer Management Considerations__:
- When messages are buffered in queues, it's essential to understand the implications of growing queue sizes:
  - Memory Management:
    - What happens when queue size exceeds available memory?
    - Does the system crash or gracefully handle the overflow?
  - Disk Persistence:
    - Does the system write messages to disk when memory is exhausted?
    - If disk storage is used, how does disk I/O impact messaging system performance?
  - Performance Impact:
    - How does increasing queue size affect overall system throughput?
    - What are the latency implications of different buffering strategies?

#### Fault Tolerance and Message Durability

What happens when nodes fail or go offline temporarily? Will messages be lost?

__Message Loss Tolerance Assessment__:
- Acceptable Loss: Can the system afford to lose some messages?
- Zero Loss Requirement: If message loss is unacceptable, persistence mechanisms are mandatory

__System-Specific Trade-offs__:
- Different systems have varying tolerance levels based on business requirements
- Financial systems typically require zero message loss
- Analytics systems might tolerate some data loss for better performance
- Real-time gaming systems might prioritize low latency over perfect delivery

__Persistence Strategies__:
- In-memory only: Fast but vulnerable to data loss
- Write-ahead logging: Balances performance and durability
- Replicated storage: Provides high availability and fault tolerance
- Hybrid approaches: Combine multiple strategies based on message criticality

## Stream Applications Across Domains

Whether it's database change streams, network packet flows, multimedia streaming, IoT sensor data, or financial market feeds - they all embody the same fundamental concept: ___processing continuous sequences of data elements as they arrive, enabling real-time insights and immediate responses___. This essence transcends specific technologies and domains, making stream processing a universal paradigm in modern computing systems.

Streams are fundamental to many modern systems:
- **Real-time Analytics**: Processing user behavior data as it happens
- **IoT Data Processing**: Handling sensor data from connected devices
- **Financial Trading**: Processing market data and executing trades
- **Social Media**: Managing user interactions and content feeds
- **Network Protocols**: [Stream in HTTP2](https://klarciel.net/wiki/network/network-binary-based-protocol/)

## Java Stream

Java Stream ì€ ê¸°ë³¸ ìŠ¤íŠ¸ë¦¼ì˜ í•µì‹¬ ì² í•™ì„ ì°¨ìš©í–ˆì§€ë§Œ, ìœ í•œí•œ ì»¬ë ‰ì…˜ ì²˜ë¦¬ì— íŠ¹í™”ëœ API ì´ë‹¤.

```java
// ğŸ“Š ê¸°ë³¸ ìŠ¤íŠ¸ë¦¼ (ë¬´í•œ, ì‹œê°„ ê¸°ë°˜)
// - ê´‘ê³  í´ë¦­ ì´ë²¤íŠ¸ê°€ ê³„ì† ë°œìƒ
// - ë°ì´í„°ê°€ ì‹œê°„ì— ë”°ë¼ ëŠì„ì—†ì´ ìƒì„±
// - "ì™„ë£Œ"ë¼ëŠ” ê°œë…ì´ ì—†ìŒ

ì‹¤ì‹œê°„ ê´‘ê³  í´ë¦­ ìŠ¤íŠ¸ë¦¼:
2024-01-15 10:00:01 â†’ Click Event 1
2024-01-15 10:00:02 â†’ Click Event 2  
2024-01-15 10:00:03 â†’ Click Event 3
... (ë¬´í•œíˆ ê³„ì†) ...

// â˜• Java Stream (ìœ í•œ, ì»¬ë ‰ì…˜ ê¸°ë°˜)
// - ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ë°ì´í„° ì»¬ë ‰ì…˜ ì²˜ë¦¬
// - ëª…í™•í•œ ì‹œì‘ê³¼ ëì´ ìˆìŒ
// - í•œ ë²ˆ ì†Œë¹„ë˜ë©´ ì¬ì‚¬ìš© ë¶ˆê°€

List<ClickEvent> events = Arrays.asList(
    new ClickEvent("ad1", "user1"),
    new ClickEvent("ad2", "user2"),
    new ClickEvent("ad3", "user1")
); // ê³ ì •ëœ í¬ê¸°

events.stream()
    .filter(event -> "user1".equals(event.getUserId()))
    .count(); // ì²˜ë¦¬ ì™„ë£Œ, ìŠ¤íŠ¸ë¦¼ ì†Œë¹„ë¨
```

### Continuous Processing vs Batch Processing

__Continuous Processing__:

```java
// ğŸ“Š ê¸°ë³¸ ìŠ¤íŠ¸ë¦¼: ì—°ì†ì  ì²˜ë¦¬ (Continuous Processing)
public class RealTimeAdClickProcessor {
    
    // ë¬´í•œ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ - ì´ë²¤íŠ¸ê°€ ì˜¬ ë•Œë§ˆë‹¤ ì¦‰ì‹œ ì²˜ë¦¬
    @EventListener
    public void processClickEvent(ClickEvent event) {
        // ì‹¤ì‹œê°„ìœ¼ë¡œ ê³„ì† ì²˜ë¦¬
        updateClickCount(event.getAdId());
        updateUserProfile(event.getUserId());
        
        // ìœˆë„ìš° ê¸°ë°˜ ì§‘ê³„ (ì˜ˆ: 1ë¶„ë§ˆë‹¤)
        if (isWindowComplete()) {
            aggregateLastMinuteClicks();
        }
    }
    
    // ì‹œê°„ ìœˆë„ìš° ê¸°ë°˜ ì²˜ë¦¬
    @Scheduled(fixedRate = 60000) // ë§¤ 1ë¶„
    public void processTimeWindow() {
        // ì§€ë‚œ 1ë¶„ê°„ì˜ ì´ë²¤íŠ¸ ì§‘ê³„
        long clicksInLastMinute = getClicksInTimeWindow(
            Instant.now().minus(1, ChronoUnit.MINUTES),
            Instant.now()
        );
        
        publishMetrics(clicksInLastMinute);
    }
}
```

__Batch Processing__:

```java
// â˜• Java Stream: ë°°ì¹˜ ì²˜ë¦¬ (Batch Processing)
public class BatchAdClickProcessor {
    
    public void processDailyClicks() {
        // í•˜ë£¨ì¹˜ ë°ì´í„°ë¥¼ í•œ ë²ˆì— ì²˜ë¦¬
        List<ClickEvent> dailyEvents = getDailyClickEvents();
        
        // í•œ ë²ˆì˜ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ëª¨ë“  ì²˜ë¦¬ ì™„ë£Œ
        Map<String, Long> adClickCounts = dailyEvents.stream()
            .collect(Collectors.groupingBy(
                ClickEvent::getAdId,
                Collectors.counting()
            ));
        
        // ì²˜ë¦¬ ì™„ë£Œ - ìŠ¤íŠ¸ë¦¼ ì†Œë¹„ë¨
        saveResults(adClickCounts);
    }
}
```

### Pipelining

```java
// ğŸ”„ ê¸°ë³¸ ìŠ¤íŠ¸ë¦¼ì˜ íŒŒì´í”„ë¼ì¸ ê°œë…ì„ Java Streamì´ ì°¨ìš©

// ê¸°ë³¸ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸:
// Raw Log â†’ Parse â†’ Filter â†’ Transform â†’ Aggregate â†’ Output

// Java Streamì˜ ë™ì¼í•œ ê°œë…:
clickEvents.stream()
    .filter(event -> event.getTimestamp().isAfter(yesterday))  // Filter
    .map(event -> new ProcessedEvent(event))                   // Transform  
    .collect(Collectors.groupingBy(                            // Aggregate
        ProcessedEvent::getAdId,
        Collectors.counting()
    ));

// ì‹¤ì œ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ ì‹œìŠ¤í…œ (Apache Kafka Streams)
KStream<String, ClickEvent> clickStream = builder.stream("click-events");

clickStream
    .filter((key, event) -> event.isValid())                  // Filter
    .mapValues(event -> enrichEvent(event))                   // Transform
    .groupByKey()                                              // Group
    .windowedBy(TimeWindows.of(Duration.ofMinutes(1)))        // Window
    .count()                                                   // Aggregate
    .toStream()
    .to("click-counts");                                       // Output
```

### Lazy Evaluation

```java
// ğŸ”„ ê¸°ë³¸ ìŠ¤íŠ¸ë¦¼: ì´ë²¤íŠ¸ ê¸°ë°˜ ì§€ì—° ì²˜ë¦¬
public class StreamProcessor {
    
    // ì´ë²¤íŠ¸ê°€ ì‹¤ì œë¡œ ë„ì°©í•  ë•Œê¹Œì§€ ëŒ€ê¸°
    public void setupEventProcessor() {
        kafkaConsumer.subscribe(Arrays.asList("click-events"));
        
        while (true) {
            ConsumerRecords<String, ClickEvent> records = kafkaConsumer.poll(Duration.ofMillis(100));
            
            // ì‹¤ì œ ë°ì´í„°ê°€ ìˆì„ ë•Œë§Œ ì²˜ë¦¬ ì‹œì‘
            for (ConsumerRecord<String, ClickEvent> record : records) {
                processEvent(record.value()); // ì§€ì—° í‰ê°€
            }
        }
    }
}

// â˜• Java Stream: í„°ë¯¸ë„ ì—°ì‚°ê¹Œì§€ ì§€ì—°
public class JavaStreamExample {
    
    public void demonstrateLazyEvaluation() {
        List<ClickEvent> events = getClickEvents();
        
        Stream<ProcessedEvent> processedStream = events.stream()
            .peek(e -> System.out.println("Processing: " + e)) // ì•„ì§ ì‹¤í–‰ ì•ˆë¨
            .filter(event -> event.isValid())                  // ì•„ì§ ì‹¤í–‰ ì•ˆë¨
            .map(event -> new ProcessedEvent(event));          // ì•„ì§ ì‹¤í–‰ ì•ˆë¨
        
        // í„°ë¯¸ë„ ì—°ì‚°ì´ í˜¸ì¶œë  ë•Œ ë¹„ë¡œì†Œ ì‹¤í–‰
        long count = processedStream.count(); // ì´ë•Œ ëª¨ë“  ì¤‘ê°„ ì—°ì‚° ì‹¤í–‰
    }
}
```

### Functional Chaining

```java
// ğŸ”„ ê¸°ë³¸ ìŠ¤íŠ¸ë¦¼: ë°ì´í„° ë³€í™˜ íŒŒì´í”„ë¼ì¸
public class AdClickPipeline {
    
    // ì›ì‹œ ë¡œê·¸ â†’ êµ¬ì¡°í™”ëœ ì´ë²¤íŠ¸ â†’ ì§‘ê³„ ê²°ê³¼
    public void processLogFile(String logFilePath) {
        try (Stream<String> lines = Files.lines(Paths.get(logFilePath))) {
            
            Map<String, Long> results = lines
                .map(this::parseLogLine)           // String â†’ ClickEvent
                .filter(Objects::nonNull)          // ìœ íš¨í•œ ì´ë²¤íŠ¸ë§Œ
                .filter(this::isValidTimeRange)    // ì‹œê°„ ë²”ìœ„ í•„í„°
                .map(this::enrichWithUserData)     // ì‚¬ìš©ì ë°ì´í„° ë³´ê°•
                .collect(Collectors.groupingBy(    // ê´‘ê³ ë³„ ì§‘ê³„
                    ClickEvent::getAdId,
                    Collectors.counting()
                ));
            
            publishResults(results);
        }
    }
    
    private ClickEvent parseLogLine(String line) {
        // ë¡œê·¸ íŒŒì‹± ë¡œì§
        String[] parts = line.split(",");
        return new ClickEvent(parts[0], parts[1], Instant.parse(parts[2]));
    }
}

// â˜• Java Stream: ë™ì¼í•œ ë³€í™˜ ì²´ì¸ ê°œë…
public class JavaStreamTransformation {
    
    public void processClickEvents(List<ClickEvent> events) {
        Map<String, Double> avgClicksByHour = events.stream()
            .filter(event -> event.getTimestamp().isAfter(yesterday))
            .map(event -> new HourlyEvent(event))
            .collect(Collectors.groupingBy(
                HourlyEvent::getHour,
                Collectors.averagingLong(HourlyEvent::getClickCount)
            ));
    }
}
```

## Reactive Streams

__[Reactive Streams](https://www.reactive-streams.org/)__:

![](/resource/wiki/architecture-stream/reactive-streams.png)

- __[Reactive Manifesto](https://reactivemanifesto.org/)__

### Infinity Stream vs Traditional Stream

```java
// ğŸ“Š ë¬´í•œ ìŠ¤íŠ¸ë¦¼ì˜ ê¸°ë³¸ íŠ¹ì„±
public class InfiniteStreamCharacteristics {
    
    // 1. ëì—†ëŠ” ë°ì´í„° ìƒì„±
    public void demonstrateInfiniteNature() {
        // ì‚¬ìš©ì í´ë¦­ì€ ì„œë¹„ìŠ¤ê°€ ì‚´ì•„ìˆëŠ” í•œ ê³„ì† ë°œìƒ
        while (serviceIsRunning) {
            ClickEvent event = waitForNextClick(); // ë¬´í•œ ëŒ€ê¸°
            processEvent(event);
        }
    }
    
    // 2. ì‹œê°„ ê¸°ë°˜ ìœˆë„ìš°
    public void timeBasedProcessing() {
        // ë°ì´í„°ë¥¼ ì‹œê°„ ë‹¨ìœ„ë¡œ ë¶„í•  ì²˜ë¦¬
        processWindow(
            Instant.now().minus(Duration.ofMinutes(5)), // 5ë¶„ ì „ë¶€í„°
            Instant.now()                               // ì§€ê¸ˆê¹Œì§€
        );
    }
    
    // 3. ë°±í”„ë ˆì…” (Backpressure) í•„ìš”
    public void handleBackpressure() {
        // ìƒì‚°ìê°€ ì†Œë¹„ìë³´ë‹¤ ë¹ ë¥¼ ë•Œ ì••ë ¥ ì¡°ì ˆ
        if (eventQueue.size() > MAX_QUEUE_SIZE) {
            // ìƒì‚° ì†ë„ ì¡°ì ˆ ë˜ëŠ” ì´ë²¤íŠ¸ ë“œë¡­
            throttleProducer();
        }
    }
}
```

__ì „í†µì ì¸ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ì˜ í•œê³„__:

```java
// ì „í†µì ì¸ ë°©ì‹ì˜ ë¬¸ì œì 
public class TraditionalStreamProcessing {
    
    // ë¬¸ì œ 1: ë¸”ë¡œí‚¹ I/O
    public void blockingApproach() {
        while (true) {
            String data = inputStream.readLine(); // ë¸”ë¡œí‚¹!
            
            // ë°ì´í„°ê°€ ì˜¬ ë•Œê¹Œì§€ ìŠ¤ë ˆë“œê°€ ëŒ€ê¸°
            // ë§ì€ ìŠ¤ë ˆë“œ í•„ìš” â†’ ë©”ëª¨ë¦¬ ë¶€ì¡±
            processData(data);
        }
    }
    
    // ë¬¸ì œ 2: ë°±í”„ë ˆì…” ì²˜ë¦¬ ì–´ë ¤ì›€
    public void backpressureIssue() {
        BlockingQueue<Event> queue = new ArrayBlockingQueue<>(1000);
        
        // ìƒì‚°ì
        new Thread(() -> {
            while (true) {
                Event event = generateEvent();
                try {
                    queue.put(event); // íê°€ ê°€ë“ ì°¨ë©´ ë¸”ë¡œí‚¹
                } catch (InterruptedException e) {
                    // ì˜ˆì™¸ ì²˜ë¦¬
                }
            }
        }).start();
        
        // ì†Œë¹„ìê°€ ëŠë¦¬ë©´ ì „ì²´ ì‹œìŠ¤í…œ ë¸”ë¡œí‚¹
    }
    
    // ë¬¸ì œ 3: ì—ëŸ¬ ì „íŒŒ ì–´ë ¤ì›€
    public void errorHandling() {
        try {
            processInfiniteStream();
        } catch (Exception e) {
            // í•˜ë‚˜ì˜ ì—ëŸ¬ê°€ ì „ì²´ ìŠ¤íŠ¸ë¦¼ì„ ì¤‘ë‹¨ì‹œí‚´
            // ë³µêµ¬ ë¡œì§ ë³µì¡
        }
    }
}
```

### Implementation Reactive Streams Spec

```java
// ğŸ”„ Reactorì˜ ê¸°ë³¸ êµ¬ì„± ìš”ì†Œ
import reactor.core.publisher.Flux;
import reactor.core.publisher.Mono;
import reactor.core.scheduler.Schedulers;

public class ReactorBasics {
    
    // Mono: 0-1ê°œ ìš”ì†Œë¥¼ ë¹„ë™ê¸°ë¡œ ì²˜ë¦¬
    public Mono<String> singleValue() {
        return Mono.just("Hello Reactor")
            .map(String::toUpperCase)
            .delayElement(Duration.ofSeconds(1)); // ë¹„ë™ê¸° ì§€ì—°
    }
    
    // Flux: 0-Nê°œ ìš”ì†Œë¥¼ ë¹„ë™ê¸°ë¡œ ì²˜ë¦¬ (ë¬´í•œ ìŠ¤íŠ¸ë¦¼ ê°€ëŠ¥)
    public Flux<Integer> infiniteStream() {
        return Flux.interval(Duration.ofSeconds(1)) // 1ì´ˆë§ˆë‹¤ ìˆ«ì ìƒì„±
            .map(i -> i.intValue())
            .take(Duration.ofMinutes(5)); // 5ë¶„ê°„ë§Œ ì‹¤í–‰
    }
    
    // ë°±í”„ë ˆì…” ìë™ ì²˜ë¦¬
    public Flux<String> backpressureHandling() {
        return Flux.range(1, 1000000) // 100ë§Œê°œ ìš”ì†Œ
            .map(i -> "Item " + i)
            .onBackpressureBuffer(1000) // ë²„í¼ í¬ê¸° ì œí•œ
            .publishOn(Schedulers.parallel()); // ë³‘ë ¬ ì²˜ë¦¬
    }
}
```

__ë¬´í•œ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ ì˜ˆì œ__:

```java
// ğŸ“Š ì‹¤ì‹œê°„ ê´‘ê³  í´ë¦­ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬
@Service
public class AdClickStreamProcessor {
    
    private final Sinks.Many<ClickEvent> clickSink = Sinks.many().multicast().onBackpressureBuffer();
    
    // ë¬´í•œ í´ë¦­ ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¼ ìƒì„±
    public Flux<ClickEvent> createClickStream() {
        return clickSink.asFlux()
            .doOnSubscribe(subscription -> 
                log.info("ìƒˆë¡œìš´ êµ¬ë…ìê°€ í´ë¦­ ìŠ¤íŠ¸ë¦¼ì— ì—°ê²°ë¨"))
            .doOnCancel(() -> 
                log.info("êµ¬ë…ìê°€ í´ë¦­ ìŠ¤íŠ¸ë¦¼ì—ì„œ ì—°ê²° í•´ì œë¨"));
    }
    
    // ì‹¤ì‹œê°„ í´ë¦­ ì§‘ê³„ (1ë¶„ ìœˆë„ìš°)
    public Flux<ClickAggregation> realTimeAggregation() {
        return createClickStream()
            .window(Duration.ofMinutes(1)) // 1ë¶„ ìœˆë„ìš°
            .flatMap(window -> 
                window.groupBy(ClickEvent::getAdId)
                    .flatMap(group -> 
                        group.count()
                            .map(count -> new ClickAggregation(
                                group.key(), 
                                count, 
                                Instant.now()
                            ))
                    )
            )
            .doOnNext(aggregation -> 
                log.info("ê´‘ê³  {} í´ë¦­ ìˆ˜: {}", 
                    aggregation.getAdId(), aggregation.getCount()));
    }
    
    // ì´ìƒ íŒ¨í„´ ê°ì§€
    public Flux<AlertEvent> anomalyDetection() {
        return realTimeAggregation()
            .buffer(Duration.ofMinutes(5), Duration.ofMinutes(1)) // 5ë¶„ ìŠ¬ë¼ì´ë”© ìœˆë„ìš°
            .map(this::detectAnomalies)
            .filter(Optional::isPresent)
            .map(Optional::get);
    }
    
    private Optional<AlertEvent> detectAnomalies(List<ClickAggregation> aggregations) {
        double avgClicks = aggregations.stream()
            .mapToLong(ClickAggregation::getCount)
            .average()
            .orElse(0.0);
            
        long maxClicks = aggregations.stream()
            .mapToLong(ClickAggregation::getCount)
            .max()
            .orElse(0L);
            
        // í‰ê· ì˜ 3ë°° ì´ìƒì´ë©´ ì´ìƒ íŒ¨í„´
        if (maxClicks > avgClicks * 3) {
            return Optional.of(new AlertEvent(
                "í´ë¦­ ê¸‰ì¦ ê°ì§€", 
                maxClicks, 
                avgClicks
            ));
        }
        
        return Optional.empty();
    }
    
    // ì™¸ë¶€ì—ì„œ í´ë¦­ ì´ë²¤íŠ¸ ì£¼ì…
    public void emitClickEvent(ClickEvent event) {
        clickSink.tryEmitNext(event);
    }
}
```

__ë°±í”„ë ˆì…” ì²˜ë¦¬ ì „ëµ__:

```java
// ğŸ”„ ë‹¤ì–‘í•œ ë°±í”„ë ˆì…” ì „ëµ
@Component
public class BackpressureStrategies {
    
    // ì „ëµ 1: ë²„í¼ë§
    public Flux<ProcessedEvent> bufferingStrategy(Flux<RawEvent> source) {
        return source
            .onBackpressureBuffer(
                10000, // ë²„í¼ í¬ê¸°
                event -> log.warn("ì´ë²¤íŠ¸ ë“œë¡­ë¨: {}", event), // ë“œë¡­ ì½œë°±
                BufferOverflowStrategy.DROP_OLDEST // ì˜¤ë˜ëœ ê²ƒë¶€í„° ë“œë¡­
            )
            .map(this::processEvent)
            .publishOn(Schedulers.parallel());
    }
    
    // ì „ëµ 2: ìƒ˜í”Œë§
    public Flux<ProcessedEvent> samplingStrategy(Flux<RawEvent> source) {
        return source
            .sample(Duration.ofSeconds(1)) // 1ì´ˆë§ˆë‹¤ ìµœì‹  ê°’ë§Œ ìƒ˜í”Œë§
            .map(this::processEvent);
    }
    
    // ì „ëµ 3: ë°°ì¹˜ ì²˜ë¦¬
    public Flux<List<ProcessedEvent>> batchingStrategy(Flux<RawEvent> source) {
        return source
            .buffer(Duration.ofSeconds(5)) // 5ì´ˆë§ˆë‹¤ ë°°ì¹˜ ì²˜ë¦¬
            .filter(batch -> !batch.isEmpty())
            .map(batch -> batch.stream()
                .map(this::processEvent)
                .collect(Collectors.toList()));
    }
    
    // ì „ëµ 4: ë™ì  ì¡°ì ˆ
    public Flux<ProcessedEvent> adaptiveStrategy(Flux<RawEvent> source) {
        return source
            .onBackpressureBuffer()
            .publishOn(Schedulers.parallel())
            .map(event -> {
                // ì²˜ë¦¬ ì‹œê°„ ì¸¡ì •
                long startTime = System.currentTimeMillis();
                ProcessedEvent result = processEvent(event);
                long processingTime = System.currentTimeMillis() - startTime;
                
                // ì²˜ë¦¬ ì‹œê°„ì´ ê¸¸ë©´ ê²½ê³ 
                if (processingTime > 1000) {
                    log.warn("ì²˜ë¦¬ ì‹œê°„ ì§€ì—°: {}ms", processingTime);
                }
                
                return result;
            });
    }
    
    private ProcessedEvent processEvent(RawEvent event) {
        // ì‹¤ì œ ì´ë²¤íŠ¸ ì²˜ë¦¬ ë¡œì§
        return new ProcessedEvent(event.getId(), event.getData().toUpperCase());
    }
}
```

__Websocket__:

```java
// ğŸŒ WebSocket + Reactor ì‹¤ì‹œê°„ í†µì‹ 
@Controller
public class RealtimeWebSocketController {
    
    private final SystemMonitoringService monitoringService;
    
    @MessageMapping("metrics.subscribe")
    public Flux<MetricEvent> subscribeToMetrics() {
        return monitoringService.combinedMetricsStream()
            .doOnSubscribe(subscription -> 
                log.info("í´ë¼ì´ì–¸íŠ¸ê°€ ë©”íŠ¸ë¦­ ìŠ¤íŠ¸ë¦¼ êµ¬ë… ì‹œì‘"))
            .doOnCancel(() -> 
                log.info("í´ë¼ì´ì–¸íŠ¸ê°€ ë©”íŠ¸ë¦­ ìŠ¤íŠ¸ë¦¼ êµ¬ë… ì·¨ì†Œ"))
            .doOnError(error -> 
                log.error("ë©”íŠ¸ë¦­ ìŠ¤íŠ¸ë¦¼ ì—ëŸ¬", error));
    }
    
    @MessageMapping("alerts.subscribe")
    public Flux<AlertEvent> subscribeToAlerts() {
        return monitoringService.alertStream()
            .doOnNext(alert -> 
                log.info("ì•Œë¦¼ ì „ì†¡: {}", alert.getMessage()));
    }
    
    // íŠ¹ì • ë©”íŠ¸ë¦­ë§Œ êµ¬ë…
    @MessageMapping("metrics.subscribe.{metricName}")
    public Flux<MetricEvent> subscribeToSpecificMetric(@DestinationVariable String metricName) {
        return monitoringService.combinedMetricsStream()
            .filter(metric -> metricName.equals(metric.getName()))
            .take(Duration.ofMinutes(30)); // 30ë¶„ í›„ ìë™ êµ¬ë… í•´ì œ
    }
}
```

__Error Handling & Recovery__:

```java
// ğŸ›¡ï¸ ì—ëŸ¬ ì²˜ë¦¬ ë° ë³µêµ¬
@Service
public class ResilientStreamProcessor {
    
    // ì—ëŸ¬ ë³µêµ¬ ì „ëµ
    public Flux<ProcessedEvent> resilientProcessing(Flux<RawEvent> source) {
        return source
            .map(this::processEvent)
            .onErrorContinue((error, event) -> {
                // ê°œë³„ ì´ë²¤íŠ¸ ì—ëŸ¬ëŠ” ë¡œê·¸ë§Œ ë‚¨ê¸°ê³  ê³„ì† ì§„í–‰
                log.error("ì´ë²¤íŠ¸ ì²˜ë¦¬ ì‹¤íŒ¨: {}", event, error);
                meterRegistry.counter("event.processing.error").increment();
            })
            .retry(3) // ì „ì²´ ìŠ¤íŠ¸ë¦¼ ì—ëŸ¬ ì‹œ 3ë²ˆ ì¬ì‹œë„
            .onErrorResume(error -> {
                // ìµœì¢… ì‹¤íŒ¨ ì‹œ ëŒ€ì²´ ìŠ¤íŠ¸ë¦¼ ì œê³µ
                log.error("ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ ìµœì¢… ì‹¤íŒ¨, ëŒ€ì²´ ìŠ¤íŠ¸ë¦¼ìœ¼ë¡œ ì „í™˜", error);
                return createFallbackStream();
            });
    }
    
    // ì„œí‚· ë¸Œë ˆì´ì»¤ íŒ¨í„´
    public Flux<ProcessedEvent> circuitBreakerProcessing(Flux<RawEvent> source) {
        CircuitBreaker circuitBreaker = CircuitBreaker.ofDefaults("eventProcessor");
        
        return source
            .map(event -> circuitBreaker.executeSupplier(() -> processEvent(event)))
            .onErrorMap(CallNotPermittedException.class, 
                ex -> new ServiceUnavailableException("ì„œë¹„ìŠ¤ ì¼ì‹œ ì¤‘ë‹¨"))
            .retryWhen(Retry.backoff(3, Duration.ofSeconds(1))
                .filter(throwable -> !(throwable instanceof ServiceUnavailableException)));
    }
    
    // íƒ€ì„ì•„ì›ƒ ì²˜ë¦¬
    public Flux<ProcessedEvent> timeoutProcessing(Flux<RawEvent> source) {
        return source
            .flatMap(event -> 
                processEventAsync(event)
                    .timeout(Duration.ofSeconds(5)) // 5ì´ˆ íƒ€ì„ì•„ì›ƒ
                    .onErrorReturn(TimeoutException.class, 
                        new ProcessedEvent(event.getId(), "TIMEOUT"))
            );
    }
    
    private Mono<ProcessedEvent> processEventAsync(RawEvent event) {
        return Mono.fromCallable(() -> processEvent(event))
            .subscribeOn(Schedulers.boundedElastic());
    }
    
    private Flux<ProcessedEvent> createFallbackStream() {
        return Flux.interval(Duration.ofSeconds(10))
            .map(i -> new ProcessedEvent("fallback-" + i, "FALLBACK_DATA"));
    }
}
```

### Data streaming to NDJSON Format

Flux ë¥¼ ì•„ë˜ ì²˜ëŸ¼ ì‚¬ìš©í•˜ë©´ NDJSON í˜•ì‹ìœ¼ë¡œ ë°ì´í„°ê°€ ìŠ¤íŠ¸ë¦¬ë° ëœë‹¤. NDJSON ì€ ë‹¤ìŒê³¼ ê°™ì´ new line ìœ¼ë¡œ row ë¥¼ ìª¼ê°œëŠ” í˜•ì‹ì´ë‹¤.

```
{"json":"object"}\n
{"json":"object"}\n
```

__Flux__:

```java
@GetMapping(path="/coupons-stream", produces=APPLICATION_NDJSON)
public Flux<CouponDto> getCouponStream(CouponSearchParams params) {  
    return couponSearchService.findFlux(params)
        .map(CouponDto::from);
}
```

- [streaming API ë¥¼ ì‚¬ìš©í•œ ë„¤ì´ë²„í˜ì´ì˜ ëŒ€í˜• XLSX íŒŒì¼ ë‹¤ìš´ë¡œë“œ êµ¬í˜„](https://d2.naver.com/helloworld/9423440)

## HTTP2

### Pipelining Processing

```java
// ğŸ”„ HTTP/2ì˜ íŒŒì´í”„ë¼ì¸ ê°œë…
public class HTTP2Pipeline {
    
    // ì „í†µì ì¸ ìŠ¤íŠ¸ë¦¼ íŒŒì´í”„ë¼ì¸
    public void traditionalStreamPipeline() {
        // Input â†’ Filter â†’ Transform â†’ Output
        inputStream
            .filter(data -> data.isValid())
            .map(data -> transform(data))
            .forEach(result -> output(result));
    }
    
    // HTTP/2ì˜ ìœ ì‚¬í•œ íŒŒì´í”„ë¼ì¸
    public void http2Pipeline() {
        // Request â†’ Frame â†’ Multiplex â†’ Response
        
        // 1. ìš”ì²­ì„ í”„ë ˆì„ìœ¼ë¡œ ë¶„í• 
        List<Frame> frames = splitIntoFrames(httpRequest);
        
        // 2. ìŠ¤íŠ¸ë¦¼ IDë¡œ ë©€í‹°í”Œë ‰ì‹±
        frames.forEach(frame -> {
            frame.setStreamId(streamId);
            connection.sendFrame(frame); // ì—°ì†ì  ì „ì†¡
        });
        
        // 3. ì‘ë‹µ í”„ë ˆì„ë“¤ì„ ìŠ¤íŠ¸ë¦¼ë³„ë¡œ ì¬ì¡°ë¦½
        connection.onFrameReceived(frame -> {
            if (frame.getStreamId() == streamId) {
                assembleResponse(frame); // ìŠ¤íŠ¸ë¦¼ ì¬êµ¬ì„±
            }
        });
    }
}
```

### Flow Control

```java
// ğŸ”„ HTTP/2ì˜ í”Œë¡œìš° ì»¨íŠ¸ë¡¤ = ìŠ¤íŠ¸ë¦¼ì˜ ë°±í”„ë ˆì…”
public class HTTP2FlowControl {
    
    private int connectionWindowSize = 65535;  // ì—°ê²° ë ˆë²¨ ìœˆë„ìš°
    private int streamWindowSize = 65535;      // ìŠ¤íŠ¸ë¦¼ ë ˆë²¨ ìœˆë„ìš°
    
    // ìŠ¤íŠ¸ë¦¼ ë°±í”„ë ˆì…” êµ¬í˜„
    public void sendData(int streamId, byte[] data) {
        int dataSize = data.length;
        
        // 1. ì—°ê²° ë ˆë²¨ í”Œë¡œìš° ì»¨íŠ¸ë¡¤ í™•ì¸
        if (connectionWindowSize < dataSize) {
            // ë°±í”„ë ˆì…” ë°œìƒ - ì „ì†¡ ëŒ€ê¸°
            waitForWindowUpdate();
        }
        
        // 2. ìŠ¤íŠ¸ë¦¼ ë ˆë²¨ í”Œë¡œìš° ì»¨íŠ¸ë¡¤ í™•ì¸  
        if (streamWindowSize < dataSize) {
            // ìŠ¤íŠ¸ë¦¼ë³„ ë°±í”„ë ˆì…” - í•´ë‹¹ ìŠ¤íŠ¸ë¦¼ë§Œ ëŒ€ê¸°
            waitForStreamWindowUpdate(streamId);
        }
        
        // 3. ë°ì´í„° ì „ì†¡ ë° ìœˆë„ìš° í¬ê¸° ê°ì†Œ
        sendDataFrame(streamId, data);
        connectionWindowSize -= dataSize;
        streamWindowSize -= dataSize;
    }
    
    // ìœˆë„ìš° ì—…ë°ì´íŠ¸ ìˆ˜ì‹  (ë°±í”„ë ˆì…” í•´ì œ)
    public void onWindowUpdate(int streamId, int increment) {
        if (streamId == 0) {
            // ì—°ê²° ë ˆë²¨ ìœˆë„ìš° ì—…ë°ì´íŠ¸
            connectionWindowSize += increment;
        } else {
            // íŠ¹ì • ìŠ¤íŠ¸ë¦¼ ìœˆë„ìš° ì—…ë°ì´íŠ¸
            updateStreamWindow(streamId, increment);
        }
        
        // ëŒ€ê¸° ì¤‘ì¸ ë°ì´í„° ì „ì†¡ ì¬ê°œ
        resumePendingTransmissions();
    }
}
```

### Multiplexing; Stream Interleaving

```java
// ğŸ”„ HTTP/2ì˜ ë©€í‹°í”Œë ‰ì‹± = ìŠ¤íŠ¸ë¦¼ì˜ ì¸í„°ë¦¬ë¹™
public class HTTP2Multiplexing {
    
    // ì—¬ëŸ¬ ìŠ¤íŠ¸ë¦¼ì´ í•˜ë‚˜ì˜ ì—°ê²°ì„ ê³µìœ 
    public void demonstrateMultiplexing() {
        
        // ë™ì‹œì— ì—¬ëŸ¬ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬
        Map<Integer, StreamState> activeStreams = new ConcurrentHashMap<>();
        
        // ìŠ¤íŠ¸ë¦¼ 1: í° íŒŒì¼ ë‹¤ìš´ë¡œë“œ
        activeStreams.put(1, new StreamState(StreamType.FILE_DOWNLOAD));
        
        // ìŠ¤íŠ¸ë¦¼ 3: API ìš”ì²­
        activeStreams.put(3, new StreamState(StreamType.API_REQUEST));
        
        // ìŠ¤íŠ¸ë¦¼ 5: ì‹¤ì‹œê°„ ë°ì´í„°
        activeStreams.put(5, new StreamState(StreamType.REALTIME_DATA));
        
        // í”„ë ˆì„ ë‹¨ìœ„ë¡œ ì¸í„°ë¦¬ë¹™ ì „ì†¡
        while (hasActiveStreams()) {
            for (Integer streamId : activeStreams.keySet()) {
                
                // ê° ìŠ¤íŠ¸ë¦¼ì—ì„œ í”„ë ˆì„ ìƒì„±
                Frame frame = generateNextFrame(streamId);
                
                if (frame != null) {
                    // ìŠ¤íŠ¸ë¦¼ë“¤ì´ ë²ˆê°ˆì•„ê°€ë©° í”„ë ˆì„ ì „ì†¡
                    sendFrame(frame);
                    
                    // ìŠ¤íŠ¸ë¦¼ ë³¸ì§ˆ: ì—°ì†ì ì´ì§€ë§Œ ì¸í„°ë¦¬ë¹™ë¨
                    logStreamProgress(streamId, frame);
                }
            }
        }
    }
    
    // ì‹¤ì œ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ì™€ ìœ ì‚¬í•œ íŒ¨í„´
    public void streamLikeProcessing() {
        
        // ê° HTTP/2 ìŠ¤íŠ¸ë¦¼ì„ Reactive Streamì²˜ëŸ¼ ì²˜ë¦¬
        Flux.fromIterable(activeStreams.keySet())
            .flatMap(streamId -> 
                processStreamFrames(streamId)
                    .takeUntil(frame -> frame.isEndStream())
            )
            .subscribe(frame -> handleFrame(frame));
    }
    
    private Flux<Frame> processStreamFrames(int streamId) {
        return Flux.create(sink -> {
            // ìŠ¤íŠ¸ë¦¼ì—ì„œ í”„ë ˆì„ì„ ì—°ì†ì ìœ¼ë¡œ ìƒì„±
            while (!isStreamClosed(streamId)) {
                Frame frame = readNextFrame(streamId);
                if (frame != null) {
                    sink.next(frame);
                }
                
                if (frame != null && frame.isEndStream()) {
                    sink.complete();
                    break;
                }
            }
        });
    }
}
```

### Server Push

```java
// ğŸ”„ Server Push = ì„œë²„ ì£¼ë„ì  ìŠ¤íŠ¸ë¦¼ ìƒì„±
public class HTTP2ServerPush {
    
    // ì „í†µì ì¸ ìŠ¤íŠ¸ë¦¼: ìƒì‚°ìê°€ ë°ì´í„°ë¥¼ í‘¸ì‹œ
    public void traditionalProducerPush() {
        
        // ìƒì‚°ìê°€ ì†Œë¹„ìì—ê²Œ ë°ì´í„°ë¥¼ í‘¸ì‹œ
        Flux<Event> eventStream = Flux.create(sink -> {
            eventProducer.onEvent(event -> {
                sink.next(event); // ìƒì‚°ì ì£¼ë„ì  í‘¸ì‹œ
            });
        });
        
        eventStream.subscribe(event -> handleEvent(event));
    }
    
    // HTTP/2 Server Push: ì„œë²„ê°€ í´ë¼ì´ì–¸íŠ¸ì—ê²Œ ë¦¬ì†ŒìŠ¤ í‘¸ì‹œ
    public void http2ServerPush(HTTP2Connection connection, HTTP2Stream mainStream) {
        
        // ë©”ì¸ ìš”ì²­ ì²˜ë¦¬
        mainStream.onHeaders(headers -> {
            if ("/index.html".equals(headers.getPath())) {
                
                // ì„œë²„ê°€ í•„ìš”í•  ê²ƒ ê°™ì€ ë¦¬ì†ŒìŠ¤ë“¤ì„ ë¯¸ë¦¬ í‘¸ì‹œ
                pushResource(connection, "/css/style.css");
                pushResource(connection, "/js/app.js");
                pushResource(connection, "/images/logo.png");
                
                // ë©”ì¸ ì‘ë‹µ ì „ì†¡
                sendMainResponse(mainStream);
            }
        });
    }
    
    private void pushResource(HTTP2Connection connection, String path) {
        // ìƒˆë¡œìš´ ìŠ¤íŠ¸ë¦¼ ìƒì„± (ì„œë²„ ì£¼ë„)
        HTTP2Stream pushStream = connection.createPushStream();
        
        // PUSH_PROMISE í”„ë ˆì„ ì „ì†¡
        PushPromiseFrame promise = new PushPromiseFrame();
        promise.setPromisedStreamId(pushStream.getId());
        promise.setHeaders(createHeaders("GET", path));
        connection.sendFrame(promise);
        
        // ì‹¤ì œ ë¦¬ì†ŒìŠ¤ ë°ì´í„° ìŠ¤íŠ¸ë¦¬ë°
        byte[] resourceData = loadResource(path);
        pushStream.sendHeaders(createResponseHeaders());
        pushStream.sendData(resourceData);
        pushStream.sendEndStream();
    }
}
```

### Implementation

__Client__:

```java
// ğŸŒ HTTP/2 í´ë¼ì´ì–¸íŠ¸ì—ì„œ ìŠ¤íŠ¸ë¦¼ í™œìš©
@Service
public class HTTP2StreamClient {
    
    private final HTTP2Connection connection;
    
    // ìŠ¤íŠ¸ë¦¼ ê¸°ë°˜ íŒŒì¼ ì—…ë¡œë“œ
    public Mono<UploadResponse> uploadFileStream(String filePath) {
        return Mono.create(sink -> {
            
            HTTP2Stream stream = connection.createStream();
            
            // í—¤ë” ì „ì†¡
            Headers headers = new Headers()
                .method("POST")
                .path("/upload")
                .contentType("application/octet-stream");
            stream.sendHeaders(headers);
            
            // íŒŒì¼ì„ ì²­í¬ ë‹¨ìœ„ë¡œ ìŠ¤íŠ¸ë¦¬ë°
            try (FileInputStream fileStream = new FileInputStream(filePath)) {
                byte[] buffer = new byte[8192];
                int bytesRead;
                
                while ((bytesRead = fileStream.read(buffer)) != -1) {
                    // ìŠ¤íŠ¸ë¦¼ì˜ ë³¸ì§ˆ: ì—°ì†ì  ë°ì´í„° ì „ì†¡
                    byte[] chunk = Arrays.copyOf(buffer, bytesRead);
                    stream.sendData(chunk);
                    
                    // ë°±í”„ë ˆì…” í™•ì¸
                    if (stream.getWindowSize() < 8192) {
                        stream.waitForWindowUpdate();
                    }
                }
                
                stream.sendEndStream();
                
            } catch (IOException e) {
                stream.sendRstStream(ErrorCode.INTERNAL_ERROR);
                sink.error(e);
            }
            
            // ì‘ë‹µ ìˆ˜ì‹ 
            stream.onComplete(response -> {
                sink.success(new UploadResponse(response));
            });
        });
    }
    
    // ë³‘ë ¬ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬
    public Flux<ApiResponse> parallelApiCalls(List<ApiRequest> requests) {
        return Flux.fromIterable(requests)
            .flatMap(request -> {
                // ê° ìš”ì²­ë§ˆë‹¤ ìƒˆë¡œìš´ ìŠ¤íŠ¸ë¦¼ ìƒì„±
                HTTP2Stream stream = connection.createStream();
                
                return Mono.create(sink -> {
                    // ìš”ì²­ ì „ì†¡
                    stream.sendHeaders(createHeaders(request));
                    stream.sendData(serialize(request));
                    stream.sendEndStream();
                    
                    // ì‘ë‹µ ìˆ˜ì‹ 
                    stream.onComplete(response -> {
                        sink.success(deserialize(response));
                    });
                    
                    stream.onError(error -> {
                        sink.error(new ApiException(error));
                    });
                });
            }, 10); // ìµœëŒ€ 10ê°œ ë™ì‹œ ìŠ¤íŠ¸ë¦¼
    }
    
    // ì‹¤ì‹œê°„ ë°ì´í„° ìŠ¤íŠ¸ë¦¬ë°
    public Flux<ServerSentEvent> subscribeToEvents() {
        return Flux.create(sink -> {
            
            HTTP2Stream stream = connection.createStream();
            
            // SSE êµ¬ë… ìš”ì²­
            Headers headers = new Headers()
                .method("GET")
                .path("/events")
                .accept("text/event-stream");
            stream.sendHeaders(headers);
            stream.sendEndStream();
            
            // ì„œë²„ë¡œë¶€í„° ì—°ì†ì ì¸ ì´ë²¤íŠ¸ ìˆ˜ì‹ 
            stream.onData(data -> {
                ServerSentEvent event = parseSSE(data);
                sink.next(event); // ìŠ¤íŠ¸ë¦¼ì˜ ë³¸ì§ˆ: ì—°ì†ì  ë°ì´í„° íë¦„
            });
            
            stream.onComplete(response -> {
                sink.complete();
            });
            
            stream.onError(error -> {
                sink.error(error);
            });
        });
    }
}
```

__Server__:

```java
// ğŸ–¥ï¸ HTTP/2 ì„œë²„ì—ì„œ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬
@RestController
public class HTTP2StreamController {
    
    // ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ
    @GetMapping(value = "/stream-data", produces = MediaType.TEXT_EVENT_STREAM_VALUE)
    public Flux<ServerSentEvent> streamData() {
        
        return Flux.interval(Duration.ofSeconds(1))
            .map(sequence -> {
                // ìŠ¤íŠ¸ë¦¼ì˜ ë³¸ì§ˆ: ì‹œê°„ì— ë”°ë¥¸ ì—°ì†ì  ë°ì´í„° ìƒì„±
                String data = generateRealtimeData();
                
                return ServerSentEvent.builder()
                    .id(String.valueOf(sequence))
                    .event("data-update")
                    .data(data)
                    .build();
            })
            .take(Duration.ofMinutes(5)) // 5ë¶„ê°„ ìŠ¤íŠ¸ë¦¬ë°
            .doOnSubscribe(subscription -> 
                log.info("í´ë¼ì´ì–¸íŠ¸ê°€ ìŠ¤íŠ¸ë¦¼ êµ¬ë… ì‹œì‘"))
            .doOnCancel(() -> 
                log.info("í´ë¼ì´ì–¸íŠ¸ê°€ ìŠ¤íŠ¸ë¦¼ êµ¬ë… ì·¨ì†Œ"));
    }
    
    // íŒŒì¼ ìŠ¤íŠ¸ë¦¬ë° ë‹¤ìš´ë¡œë“œ
    @GetMapping("/download/{fileId}")
    public ResponseEntity<StreamingResponseBody> downloadFile(@PathVariable String fileId) {
        
        StreamingResponseBody stream = outputStream -> {
            try (FileInputStream fileStream = new FileInputStream(getFilePath(fileId))) {
                
                byte[] buffer = new byte[8192];
                int bytesRead;
                
                // ìŠ¤íŠ¸ë¦¼ì˜ ë³¸ì§ˆ: ì²­í¬ ë‹¨ìœ„ ì—°ì† ì „ì†¡
                while ((bytesRead = fileStream.read(buffer)) != -1) {
                    outputStream.write(buffer, 0, bytesRead);
                    outputStream.flush();
                    
                    // HTTP/2ì˜ í”Œë¡œìš° ì»¨íŠ¸ë¡¤ì´ ìë™ìœ¼ë¡œ ë°±í”„ë ˆì…” ì²˜ë¦¬
                }
            }
        };
        
        return ResponseEntity.ok()
            .contentType(MediaType.APPLICATION_OCTET_STREAM)
            .body(stream);
    }
}
```

## Database Stream Processing

```java
// ğŸ“Š ì‹¤ì‹œê°„ ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤íŠ¸ë¦¼ ë¶„ì„
@Service
public class DatabaseStreamAnalytics {
    
    // ì‹¤ì‹œê°„ ì‚¬ìš©ì í™œë™ ë¶„ì„
    public void analyzeUserActivity() {
        
        // ì‚¬ìš©ì ë¡œê·¸ì¸ ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¼
        KStream<String, LoginEvent> loginStream = builder
            .stream("user.login.events");
            
        // ì‹¤ì‹œê°„ ì§‘ê³„: ë¶„ë‹¹ ë¡œê·¸ì¸ ìˆ˜
        KTable<Windowed<String>, Long> loginCounts = loginStream
            .groupByKey()
            .windowedBy(TimeWindows.of(Duration.ofMinutes(1)))
            .count();
            
        // ì´ìƒ íŒ¨í„´ ê°ì§€
        loginCounts.toStream()
            .filter((window, count) -> count > 1000) // ë¶„ë‹¹ 1000íšŒ ì´ˆê³¼
            .foreach((window, count) -> 
                alertService.sendAlert("ë†’ì€ ë¡œê·¸ì¸ í™œë™ ê°ì§€: " + count));
    }
    
    // ì‹¤ì‹œê°„ ì£¼ë¬¸ ì²˜ë¦¬ ìŠ¤íŠ¸ë¦¼
    public void processOrderStream() {
        
        KStream<String, OrderEvent> orderStream = builder
            .stream("orders.events");
            
        // ì£¼ë¬¸ ìƒíƒœë³„ ë¶„ê¸° ì²˜ë¦¬
        KStream<String, OrderEvent>[] branches = orderStream
            .branch(
                (key, order) -> "CREATED".equals(order.getStatus()),
                (key, order) -> "PAID".equals(order.getStatus()),
                (key, order) -> "SHIPPED".equals(order.getStatus()),
                (key, order) -> "DELIVERED".equals(order.getStatus())
            );
            
        // ê° ìƒíƒœë³„ ì²˜ë¦¬
        branches[0].foreach((key, order) -> processNewOrder(order));
        branches[1].foreach((key, order) -> processPayment(order));
        branches[2].foreach((key, order) -> updateShipping(order));
        branches[3].foreach((key, order) -> completeOrder(order));
    }
}
```

## File I/O Stream

```java
// ğŸ“ íŒŒì¼ ì‹œìŠ¤í…œì—ì„œì˜ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬
public class FileSystemStreams {
    
    // ëŒ€ìš©ëŸ‰ íŒŒì¼ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬
    public void processLargeFile(String filePath) throws IOException {
        
        // íŒŒì¼ì„ ìŠ¤íŠ¸ë¦¼ìœ¼ë¡œ ì½ì–´ ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì²˜ë¦¬
        try (Stream<String> lines = Files.lines(Paths.get(filePath))) {
            
            lines.parallel() // ë³‘ë ¬ ì²˜ë¦¬
                .filter(line -> !line.trim().isEmpty())
                .map(this::parseLine)
                .filter(Objects::nonNull)
                .forEach(this::processRecord);
        }
    }
    
    // ì‹¤ì‹œê°„ íŒŒì¼ ë³€ê²½ ê°ì§€ ìŠ¤íŠ¸ë¦¼
    public Flux<FileChangeEvent> watchFileChanges(String directoryPath) {
        
        return Flux.create(sink -> {
            try {
                WatchService watchService = FileSystems.getDefault().newWatchService();
                Path path = Paths.get(directoryPath);
                
                path.register(watchService, 
                    StandardWatchEventKinds.ENTRY_CREATE,
                    StandardWatchEventKinds.ENTRY_MODIFY,
                    StandardWatchEventKinds.ENTRY_DELETE);
                
                // ë¬´í•œ ìŠ¤íŠ¸ë¦¼: íŒŒì¼ ë³€ê²½ì‚¬í•­ ê°ì§€
                while (!Thread.currentThread().isInterrupted()) {
                    WatchKey key = watchService.take();
                    
                    for (WatchEvent<?> event : key.pollEvents()) {
                        FileChangeEvent changeEvent = new FileChangeEvent(
                            event.kind().name(),
                            event.context().toString(),
                            Instant.now()
                        );
                        
                        sink.next(changeEvent);
                    }
                    
                    key.reset();
                }
                
            } catch (Exception e) {
                sink.error(e);
            }
        });
    }
    
    // ë¡œê·¸ íŒŒì¼ ì‹¤ì‹œê°„ í…Œì¼ë§
    public Flux<String> tailLogFile(String logFilePath) {
        
        return Flux.create(sink -> {
            try (RandomAccessFile file = new RandomAccessFile(logFilePath, "r")) {
                
                // íŒŒì¼ ëìœ¼ë¡œ ì´ë™
                file.seek(file.length());
                
                while (!Thread.currentThread().isInterrupted()) {
                    String line = file.readLine();
                    
                    if (line != null) {
                        sink.next(line); // ìƒˆë¡œìš´ ë¡œê·¸ ë¼ì¸ ìŠ¤íŠ¸ë¦¬ë°
                    } else {
                        // ìƒˆë¡œìš´ ë‚´ìš©ì´ ì—†ìœ¼ë©´ ì ì‹œ ëŒ€ê¸°
                        Thread.sleep(100);
                    }
                }
                
            } catch (Exception e) {
                sink.error(e);
            }
        });
    }
}
```

## Websocket Realtime Stream

```java
// ğŸŒ WebSocket ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¼
@Component
public class WebSocketStreamHandler extends TextWebSocketHandler {
    
    private final Sinks.Many<WebSocketMessage> messageSink = 
        Sinks.many().multicast().onBackpressureBuffer();
    
    // WebSocket ë©”ì‹œì§€ ìŠ¤íŠ¸ë¦¼
    public Flux<WebSocketMessage> getMessageStream() {
        return messageSink.asFlux();
    }
    
    @Override
    public void afterConnectionEstablished(WebSocketSession session) {
        log.info("WebSocket ì—°ê²° ì„¤ì •: {}", session.getId());
        
        // ì‹¤ì‹œê°„ ë°ì´í„° ìŠ¤íŠ¸ë¦¼ì„ í´ë¼ì´ì–¸íŠ¸ì—ê²Œ ì „ì†¡
        getRealtimeDataStream()
            .subscribe(data -> {
                try {
                    session.sendMessage(new TextMessage(data));
                } catch (IOException e) {
                    log.error("ë©”ì‹œì§€ ì „ì†¡ ì‹¤íŒ¨", e);
                }
            });
    }
    
    @Override
    protected void handleTextMessage(WebSocketSession session, TextMessage message) {
        // ìˆ˜ì‹ ëœ ë©”ì‹œì§€ë¥¼ ìŠ¤íŠ¸ë¦¼ì— ë°œí–‰
        WebSocketMessage wsMessage = new WebSocketMessage(
            session.getId(), 
            message.getPayload(), 
            Instant.now()
        );
        
        messageSink.tryEmitNext(wsMessage);
    }
    
    private Flux<String> getRealtimeDataStream() {
        return Flux.interval(Duration.ofSeconds(1))
            .map(tick -> generateRealtimeData())
            .share();
    }
}
```

## Distributed Event Streaming Platform

```java
// ğŸ“¨ Kafka Streams ì²˜ë¦¬
@Service
public class KafkaStreamProcessor {
    
    // ì‹¤ì‹œê°„ ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬
    public void processEventStream() {
        
        Properties props = new Properties();
        props.put(StreamsConfig.APPLICATION_ID_CONFIG, "event-processor");
        props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
        
        StreamsBuilder builder = new StreamsBuilder();
        
        // ì‚¬ìš©ì ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¼
        KStream<String, UserEvent> userEvents = builder.stream("user-events");
        
        // ì‹¤ì‹œê°„ ì‚¬ìš©ì ì„¸ì…˜ ì¶”ì 
        KTable<String, UserSession> userSessions = userEvents
            .groupByKey()
            .aggregate(
                UserSession::new,
                (key, event, session) -> session.addEvent(event),
                Materialized.with(Serdes.String(), userSessionSerde())
            );
        
        // ì´ìƒ í–‰ë™ íŒ¨í„´ ê°ì§€
        userEvents
            .filter((key, event) -> isAnomalousEvent(event))
            .to("anomaly-alerts");
        
        // ì‹¤ì‹œê°„ ì¶”ì²œ ì‹œìŠ¤í…œ
        userEvents
            .filter((key, event) -> "PRODUCT_VIEW".equals(event.getType()))
            .groupByKey()
            .windowedBy(TimeWindows.of(Duration.ofMinutes(30)))
            .aggregate(
                ProductViewAggregation::new,
                (key, event, agg) -> agg.addView(event),
                Materialized.with(Serdes.String(), productViewSerde())
            )
            .toStream()
            .map((window, agg) -> generateRecommendations(agg))
            .to("user-recommendations");
        
        KafkaStreams streams = new KafkaStreams(builder.build(), props);
        streams.start();
    }
}
```

## Multi-Media Stream

```java
// ğŸ¥ ë©€í‹°ë¯¸ë””ì–´ ìŠ¤íŠ¸ë¦¬ë°
@RestController
public class MediaStreamController {
    
    // ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë°
    @GetMapping("/video/{videoId}")
    public ResponseEntity<StreamingResponseBody> streamVideo(
            @PathVariable String videoId,
            @RequestHeader(value = "Range", required = false) String rangeHeader) {
        
        File videoFile = getVideoFile(videoId);
        long fileSize = videoFile.length();
        
        // HTTP Range ìš”ì²­ ì²˜ë¦¬ (ë¹„ë””ì˜¤ ì‹œí‚¹)
        long start = 0;
        long end = fileSize - 1;
        
        if (rangeHeader != null) {
            String[] ranges = rangeHeader.replace("bytes=", "").split("-");
            start = Long.parseLong(ranges[0]);
            if (ranges.length > 1 && !ranges[1].isEmpty()) {
                end = Long.parseLong(ranges[1]);
            }
        }
        
        long contentLength = end - start + 1;
        final long finalStart = start;
        final long finalEnd = end;
        
        StreamingResponseBody stream = outputStream -> {
            try (RandomAccessFile file = new RandomAccessFile(videoFile, "r")) {
                
                file.seek(finalStart);
                byte[] buffer = new byte[8192];
                long bytesToRead = finalEnd - finalStart + 1;
                
                while (bytesToRead > 0) {
                    int bytesRead = file.read(buffer, 0, 
                        (int) Math.min(buffer.length, bytesToRead));
                    
                    if (bytesRead == -1) break;
                    
                    outputStream.write(buffer, 0, bytesRead);
                    bytesToRead -= bytesRead;
                }
            }
        };
        
        return ResponseEntity.status(HttpStatus.PARTIAL_CONTENT)
            .header("Content-Type", "video/mp4")
            .header("Accept-Ranges", "bytes")
            .header("Content-Length", String.valueOf(contentLength))
            .header("Content-Range", String.format("bytes %d-%d/%d", 
                finalStart, finalEnd, fileSize))
            .body(stream);
    }
    
    // ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¬ë°
    @GetMapping(value = "/audio/live", produces = "audio/mpeg")
    public Flux<DataBuffer> streamLiveAudio() {
        
        return Flux.create(sink -> {
            
            // ë§ˆì´í¬ë¡œë¶€í„° ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ìº¡ì²˜
            AudioFormat format = new AudioFormat(44100, 16, 2, true, false);
            DataLine.Info info = new DataLine.Info(TargetDataLine.class, format);
            
            try {
                TargetDataLine microphone = (TargetDataLine) AudioSystem.getLine(info);
                microphone.open(format);
                microphone.start();
                
                byte[] buffer = new byte[4096];
                
                while (!Thread.currentThread().isInterrupted()) {
                    int bytesRead = microphone.read(buffer, 0, buffer.length);
                    
                    if (bytesRead > 0) {
                        DataBuffer dataBuffer = new DefaultDataBufferFactory()
                            .wrap(Arrays.copyOf(buffer, bytesRead));
                        sink.next(dataBuffer);
                    }
                }
                
                microphone.close();
                
            } catch (Exception e) {
                sink.error(e);
            }
        });
    }
}
```

## Log Stream

```java
// ğŸ“‹ ë¡œê·¸ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬
@Service
public class LogStreamProcessor {
    
    // ELK ìŠ¤íƒê³¼ ì—°ë™í•œ ë¡œê·¸ ìŠ¤íŠ¸ë¦¼
    public void processLogStream() {
        
        // Logstashë¡œë¶€í„° ë¡œê·¸ ìŠ¤íŠ¸ë¦¼ ìˆ˜ì‹ 
        Flux<LogEntry> logStream = createLogStream();
        
        // ì‹¤ì‹œê°„ ë¡œê·¸ ë¶„ì„
        logStream
            .window(Duration.ofMinutes(1)) // 1ë¶„ ìœˆë„ìš°
            .flatMap(window -> 
                window.groupBy(LogEntry::getLevel)
                    .flatMap(levelGroup -> 
                        levelGroup.count()
                            .map(count -> new LogLevelCount(
                                levelGroup.key(), count, Instant.now()))
                    )
            )
            .subscribe(count -> updateLogMetrics(count));
        
        // ì—ëŸ¬ ë¡œê·¸ ì‹¤ì‹œê°„ ì•Œë¦¼
        logStream
            .filter(log -> "ERROR".equals(log.getLevel()))
            .buffer(Duration.ofSeconds(30)) // 30ì´ˆ ë°°ì¹˜
            .filter(errors -> errors.size() > 10) // 30ì´ˆì— 10ê°œ ì´ìƒ ì—ëŸ¬
            .subscribe(errors -> sendErrorAlert(errors));
        
        // ë³´ì•ˆ ì´ë²¤íŠ¸ ê°ì§€
        logStream
            .filter(this::isSecurityEvent)
            .groupBy(LogEntry::getSourceIp)
            .flatMap(ipGroup -> 
                ipGroup.window(Duration.ofMinutes(5))
                    .flatMap(window -> window.count())
                    .filter(count -> count > 100) // 5ë¶„ì— 100íšŒ ì´ìƒ
                    .map(count -> new SecurityAlert(ipGroup.key(), count))
            )
            .subscribe(alert -> handleSecurityAlert(alert));
    }
    
    private Flux<LogEntry> createLogStream() {
        return Flux.create(sink -> {
            
            // Kafkaì—ì„œ ë¡œê·¸ ìŠ¤íŠ¸ë¦¼ êµ¬ë…
            KafkaConsumer<String, String> consumer = createKafkaConsumer();
            consumer.subscribe(Arrays.asList("application-logs"));
            
            while (!Thread.currentThread().isInterrupted()) {
                ConsumerRecords<String, String> records = consumer.poll(Duration.ofMillis(100));
                
                for (ConsumerRecord<String, String> record : records) {
                    LogEntry logEntry = parseLogEntry(record.value());
                    sink.next(logEntry);
                }
            }
        });
    }
}
```

## IoT Data Stream

```java
// ğŸŒ¡ï¸ IoT ì„¼ì„œ ë°ì´í„° ìŠ¤íŠ¸ë¦¼
@Service
public class IoTDataStreamProcessor {
    
    // ì˜¨ë„ ì„¼ì„œ ë°ì´í„° ìŠ¤íŠ¸ë¦¼
    public Flux<TemperatureReading> processTemperatureStream() {
        
        return Flux.interval(Duration.ofSeconds(5))
            .map(tick -> readTemperatureSensor())
            .filter(reading -> reading.isValid())
            .share();
    }
    
    // ì‹¤ì‹œê°„ í™˜ê²½ ëª¨ë‹ˆí„°ë§
    public void setupEnvironmentMonitoring() {
        
        Flux<TemperatureReading> tempStream = processTemperatureStream();
        Flux<HumidityReading> humidityStream = processHumidityStream();
        Flux<AirQualityReading> airQualityStream = processAirQualityStream();
        
        // ì„¼ì„œ ë°ì´í„° í†µí•©
        Flux<EnvironmentData> combinedStream = Flux.combineLatest(
            tempStream,
            humidityStream,
            airQualityStream,
            EnvironmentData::new
        );
        
        // ì´ìƒ í™˜ê²½ ê°ì§€
        combinedStream
            .filter(this::isAbnormalEnvironment)
            .subscribe(data -> triggerEnvironmentAlert(data));
        
        // ì‹œê°„ë³„ í™˜ê²½ ë°ì´í„° ì§‘ê³„
        combinedStream
            .window(Duration.ofHours(1))
            .flatMap(window -> 
                window.reduce(new EnvironmentAggregation(),
                    (agg, data) -> agg.add(data))
            )
            .subscribe(hourlyData -> saveHourlyData(hourlyData));
    }
    
    // ìŠ¤ë§ˆíŠ¸ ë¹Œë”© ì—ë„ˆì§€ ê´€ë¦¬
    public void processEnergyStream() {
        
        Flux<EnergyReading> energyStream = createEnergyStream();
        
        // ì‹¤ì‹œê°„ ì—ë„ˆì§€ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§
        energyStream
            .window(Duration.ofMinutes(15)) // 15ë¶„ ìœˆë„ìš°
            .flatMap(window -> 
                window.reduce(0.0, (sum, reading) -> sum + reading.getConsumption())
            )
            .subscribe(consumption -> {
                if (consumption > ENERGY_THRESHOLD) {
                    optimizeEnergyUsage();
                }
            });
        
        // ì˜ˆì¸¡ì  ìœ ì§€ë³´ìˆ˜
        energyStream
            .buffer(Duration.ofDays(1)) // ì¼ì¼ ë°ì´í„°
            .map(this::analyzeEnergyPattern)
            .filter(analysis -> analysis.requiresMaintenance())
            .subscribe(analysis -> scheduleMaintenanceAlert(analysis));
    }
}
```

## Finance Stream

```java
// ğŸ’° ê¸ˆìœµ ê±°ë˜ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¼
@Service
public class FinancialStreamProcessor {
    
    // ì‹¤ì‹œê°„ ì£¼ì‹ ê°€ê²© ìŠ¤íŠ¸ë¦¼
    public Flux<StockPrice> createStockPriceStream(String symbol) {
        
        return Flux.create(sink -> {
            
            // WebSocketìœ¼ë¡œ ì‹¤ì‹œê°„ ì£¼ì‹ ë°ì´í„° ìˆ˜ì‹ 
            WebSocketClient client = new StandardWebSocketClient();
            
            client.doHandshake(new WebSocketHandler() {
                @Override
                public void afterConnectionEstablished(WebSocketSession session) {
                    // ì£¼ì‹ ì‹¬ë³¼ êµ¬ë…
                    session.sendMessage(new TextMessage(
                        "{\"action\":\"subscribe\",\"symbols\":\"" + symbol + "\"}"
                    ));
                }
                
                @Override
                protected void handleTextMessage(WebSocketSession session, TextMessage message) {
                    StockPrice price = parseStockPrice(message.getPayload());
                    sink.next(price);
                }
            }, "wss://api.stockexchange.com/stream");
        });
    }
    
    // ì‹¤ì‹œê°„ ê±°ë˜ ë¶„ì„
    public void setupTradingAnalysis() {
        
        Flux<StockPrice> priceStream = createStockPriceStream("AAPL");
        
        // ì´ë™í‰ê·  ê³„ì‚°
        priceStream
            .window(Duration.ofMinutes(5)) // 5ë¶„ ìœˆë„ìš°
            .flatMap(window -> 
                window.reduce(new MovingAverage(), 
                    (avg, price) -> avg.add(price.getPrice()))
            )
            .subscribe(movingAvg -> updateTradingIndicators(movingAvg));
        
        // ê¸‰ê²©í•œ ê°€ê²© ë³€ë™ ê°ì§€
        priceStream
            .buffer(2, 1) // ìŠ¬ë¼ì´ë”© ìœˆë„ìš°
            .filter(prices -> {
                if (prices.size() < 2) return false;
                double change = Math.abs(prices.get(1).getPrice() - prices.get(0).getPrice());
                return change > VOLATILITY_THRESHOLD;
            })
            .subscribe(prices -> triggerVolatilityAlert(prices));
        
        // ì‹¤ì‹œê°„ í¬íŠ¸í´ë¦¬ì˜¤ í‰ê°€
        priceStream
            .map(price -> calculatePortfolioValue(price))
            .distinctUntilChanged()
            .subscribe(value -> updatePortfolioValue(value));
    }
    
    // ì‚¬ê¸° ê±°ë˜ íƒì§€
    public void setupFraudDetection() {
        
        Flux<Transaction> transactionStream = createTransactionStream();
        
        // ì‹¤ì‹œê°„ ì‚¬ê¸° íŒ¨í„´ ë¶„ì„
        transactionStream
            .groupBy(Transaction::getUserId)
            .flatMap(userTransactions -> 
                userTransactions
                    .window(Duration.ofMinutes(10)) // 10ë¶„ ìœˆë„ìš°
                    .flatMap(window -> 
                        window.collectList()
                            .map(this::analyzeFraudPattern)
                            .filter(FraudAnalysis::isSuspicious)
                    )
            )
            .subscribe(suspiciousActivity -> blockSuspiciousTransaction(suspiciousActivity));
    }
}
```

## References

- Designing Data-Intensive Application / Martin Kleppmann
- System Design Interview Volume 2 / Alex Xu, Sahn Lam
- Streaming Systems / Tyler Akidau
